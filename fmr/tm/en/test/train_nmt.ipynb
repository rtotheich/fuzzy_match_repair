{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c511a1ea-b9a8-4d1c-a13d-216888aa4938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "!nproc --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9a469fb-a06a-496d-88db-1f4975c6aac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2024-03-04 17:07:19,950 INFO] Counter vocab from -1 samples.\n",
      "[2024-03-04 17:07:19,950 INFO] n_sample=-1: Build vocab on full datasets.\n",
      "[2024-03-04 17:07:24,327 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,612 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=3)\n",
      "\n",
      "[2024-03-04 17:07:24,673 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,686 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,819 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=2)\n",
      "\n",
      "[2024-03-04 17:07:24,880 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,881 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,914 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=5)\n",
      "\n",
      "[2024-03-04 17:07:24,929 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=2)\n",
      "\n",
      "[2024-03-04 17:07:24,966 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,980 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,992 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:24,993 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:25,018 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:25,056 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=2)\n",
      "\n",
      "[2024-03-04 17:07:25,092 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:25,123 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=2)\n",
      "\n",
      "[2024-03-04 17:07:25,146 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=4)\n",
      "\n",
      "[2024-03-04 17:07:25,179 INFO] * Transform statistics for corpus_1(2.78%):\n",
      "\t\t\t* FilterTooLongStats(filtered=1)\n",
      "\n",
      "[2024-03-04 17:07:25,899 INFO] Counters src: 50699\n",
      "[2024-03-04 17:07:25,899 INFO] Counters tgt: 49152\n"
     ]
    }
   ],
   "source": [
    "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68371470-5592-4943-b476-aa753afdd279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-48da986e-07f1-7a71-6326-c3e2ee409ad3)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cf4415e-6dc7-4ee3-8040-8fb44fbd9607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla T4\n",
      "Free GPU memory: 14824.5 out of: 14929.5625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "gpu_memory = torch.cuda.mem_get_info(0)\n",
    "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb60e643-70cb-4644-b1a1-d0a1c876fcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-04 17:08:56,791 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2024-03-04 17:08:56,793 INFO] Parsed 2 corpora from -data.\n",
      "[2024-03-04 17:08:56,793 INFO] Get special vocabs from Transforms: {'src': [], 'tgt': []}.\n",
      "[2024-03-04 17:08:56,965 INFO] The first 10 tokens of the vocabs are:['<unk>', '<blank>', '<s>', '</s>', '▁de', '’', '▁', ',', '▁la', '2']\n",
      "[2024-03-04 17:08:56,965 INFO] The decoder start token is: <s>\n",
      "[2024-03-04 17:08:56,965 INFO] Building model...\n",
      "[2024-03-04 17:08:58,137 INFO] Switching model to float32 for amp/apex_amp\n",
      "[2024-03-04 17:08:58,137 INFO] Non quantized layer compute is fp16\n",
      "[2024-03-04 17:08:58,543 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(50000, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0-5): 6 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(49160, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding()\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0-5): 6 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=49160, bias=True)\n",
      ")\n",
      "[2024-03-04 17:08:58,546 INFO] encoder: 44487680\n",
      "[2024-03-04 17:08:58,546 INFO] decoder: 75574280\n",
      "[2024-03-04 17:08:58,546 INFO] * number of parameters: 120061960\n",
      "[2024-03-04 17:08:58,546 INFO] Trainable parameters = {'torch.float32': 120061960, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-04 17:08:58,546 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
      "[2024-03-04 17:08:58,546 INFO]  * src vocab size = 50000\n",
      "[2024-03-04 17:08:58,546 INFO]  * tgt vocab size = 49160\n",
      "[2024-03-04 17:09:00,657 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2024-03-04 17:09:00,658 INFO] Starting training on GPU: [0]\n",
      "[2024-03-04 17:09:00,658 INFO] Start training loop and validate every 500 steps...\n",
      "[2024-03-04 17:09:00,658 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=500, tgt_seq_length=500))\n",
      "[2024-03-04 17:10:38,266 INFO] Step 100/  500; acc: 5.2; ppl: 6224.6; xent: 8.7; lr: 0.00028; sents:   43590; bsz: 3818/3339/109; 15648/13683 tok/s;     98 sec;\n",
      "[2024-03-04 17:11:51,679 INFO] Step 200/  500; acc: 16.3; ppl: 618.7; xent: 6.4; lr: 0.00056; sents:   38806; bsz: 3825/3314/97; 20843/18059 tok/s;    171 sec;\n",
      "[2024-03-04 17:13:06,199 INFO] Step 300/  500; acc: 25.4; ppl: 291.8; xent: 5.7; lr: 0.00084; sents:   40821; bsz: 3781/3271/102; 20296/17559 tok/s;    246 sec;\n",
      "[2024-03-04 17:14:20,663 INFO] Step 400/  500; acc: 30.0; ppl: 201.5; xent: 5.3; lr: 0.00112; sents:   45619; bsz: 3794/3292/114; 20379/17683 tok/s;    320 sec;\n",
      "[2024-03-04 17:15:34,580 INFO] Step 500/  500; acc: 33.9; ppl: 139.9; xent: 4.9; lr: 0.00140; sents:   41473; bsz: 3863/3302/104; 20903/17867 tok/s;    394 sec;\n",
      "[2024-03-04 17:16:06,675 INFO] valid stats calculation\n",
      "                           took: 32.09323167800903 s.\n",
      "[2024-03-04 17:16:06,676 INFO] Train perplexity: 505.089\n",
      "[2024-03-04 17:16:06,677 INFO] Train accuracy: 22.1084\n",
      "[2024-03-04 17:16:06,677 INFO] Sentences processed: 210309\n",
      "[2024-03-04 17:16:06,677 INFO] Average bsz: 3816/3304/105\n",
      "[2024-03-04 17:16:06,677 INFO] Validation perplexity: 150.456\n",
      "[2024-03-04 17:16:06,677 INFO] Validation accuracy: 34.7009\n",
      "[2024-03-04 17:16:06,677 INFO] Model is improving ppl: inf --> 150.456.\n",
      "[2024-03-04 17:16:06,677 INFO] Model is improving acc: -inf --> 34.7009.\n",
      "[2024-03-04 17:16:08,226 INFO] Saving checkpoint models/model.fren_step_500.pt\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332fa9d0-dec2-4884-a95e-3c25e12295ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-04 17:19:48,363 INFO] Loading checkpoint from models/model.fren_step_500.pt\n",
      "[2024-03-04 17:19:49,940 INFO] Loading data into the model\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/work/nlp/yue.r/miniconda/envs/dl/bin/onmt_translate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/work/nlp/yue.r/miniconda/envs/dl/lib/python3.9/site-packages/onmt/bin/translate.py\", line 67, in main\n",
      "    translate(opt)\n",
      "  File \"/work/nlp/yue.r/miniconda/envs/dl/lib/python3.9/site-packages/onmt/bin/translate.py\", line 37, in translate\n",
      "    _, _ = translator._translate(\n",
      "  File \"/work/nlp/yue.r/miniconda/envs/dl/lib/python3.9/site-packages/onmt/translate/translator.py\", line 508, in _translate\n",
      "    batch_data = self.translate_batch(batch, attn_debug)\n",
      "  File \"/work/nlp/yue.r/miniconda/envs/dl/lib/python3.9/site-packages/onmt/translate/translator.py\", line 848, in translate_batch\n",
      "    return self._translate_batch_with_strategy(batch, decode_strategy)\n",
      "  File \"/work/nlp/yue.r/miniconda/envs/dl/lib/python3.9/site-packages/onmt/translate/translator.py\", line 923, in _translate_batch_with_strategy\n",
      "    decode_strategy.advance(log_probs, attn)\n",
      "  File \"/work/nlp/yue.r/miniconda/envs/dl/lib/python3.9/site-packages/onmt/translate/beam_search.py\", line 388, in advance\n",
      "    self.is_finished_list = self.topk_ids.eq(self.eos).tolist()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!onmt_translate -model models/model.fren_step_500.pt -src /work/nlp/yue.r/opennmt/nmt_test_data/en-fr.fr-filtered.fr.test -output en.translated -gpu 0 -min_length 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bbc430f-5731-4ba8-a783-9e5b94c051a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/work/nlp/yue.r/opennmt/nmt_tut/MT-Preparation/subwording/3-desubword.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python /work/nlp/yue.r/opennmt/nmt_tut/MT-Preparation/subwording/3-desubword.py target.model en.translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d22d61d3-e288-4308-bd0b-bfe641a6b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open ‘fr.translated.desubword’ for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!head en.translated.desubword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf39265-c26b-4f26-a8ae-9578923f6864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/work/nlp/yue.r/opennmt_fr_en/compute-bleu.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python compute-bleu.py /work/nlp/yue.r/fmr/nmt_test_data/en-fr.en-filtered.en.test en.translated.desubword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53a68f70-e1a3-43a0-9d27-df4becee9cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook train_nmt.ipynb to python\n",
      "[NbConvertApp] Writing 1215 bytes to train_nmt.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to python train_nmt.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60209d7b-b8b2-47b1-858d-3b4856e085b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
